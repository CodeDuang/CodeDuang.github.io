# Prompt Engineering经验总结

【重要】Prompt Engineering一定是在大量的测试样例上总结的规律，同时也需要多次运行，判断同一prompt的多次运行情况是否稳定。再得出结论


1.当你调整prompt多次之后，发现大模型输出情况一直没有变好，说明可能是因为prompt的某一条指令被过度遵守（权重过高）。
解决方案：查看模型的输出，并对比各个规则，找到被违反最少的规则，即为被过度遵守的指令。

2.由于Prompt Engineering大部分是人工判断效果好与坏，如果资源与时间允许，可以用另外一个更高级的模型，站在模型的角度分析该prompt是否起到了比较好的效果。（适用与prompt已经调整的比较好，想要进一步提升）。

3.要是一直调整不出需要的效果，可以试下拆分功能，比如需要大模型根据客服与顾客的对话提取出产品需求，可以拆分为：根据对话提取所有需求+分析每个需求删除没用的

4.如果有输出样例，请在样例中给模型足够的自由，比如：
{'requirement': '防油','why':'是产品的功能', 'need': 'True'}   (不好)
{'requirement': '防油','why':'[这里填你的思考]', 'need': 'True/False'}  (好)

5.大模型做不了过多类别的多分类任务

6.大模型的“输出”务必结合“输入”存放在txt或者excel中，方便回溯定位大模型的问题！！！！！！

7.复杂的任务，可以让多个大模型协作完成（土豪方案）

8.大模型偶尔会输出英语，有可能是prompt中使用了比较多的“英语单词”或“英语符号”,也有可能是要求大模型的输出带有"英语符号或单词"。（只是经验，不一定正确）